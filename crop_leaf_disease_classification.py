# -*- coding: utf-8 -*-
"""Crop_leaf_disease_classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1akEUHywzUiihwRDcrp-suqrXqEHN2JeS
"""

!pip install kagglehub

import kagglehub

dataset_handle = "seroshkarim/cotton-leaf-disease-dataset"

path = kagglehub.dataset_download(dataset_handle)
print("Path to dataset files:", path)

import os

base_download_path = path
print("kagglehub base path:", base_download_path)

for p in os.listdir(base_download_path):
    print("-", p)

def find_dataset_root(base_path):
    for name in ("train", "valid", "val", "test"):
        candidate = os.path.join(base_path, name)
        if os.path.isdir(candidate):
            return base_path, candidate
    for name in os.listdir(base_path):
        p = os.path.join(base_path, name)
        if os.path.isdir(p):
            for child in ("train", "valid", "val", "test"):
                if os.path.isdir(os.path.join(p, child)):
                    return p, os.path.join(p, child)
    # 3) If no train/valid folders, find a folder that contains class subfolders or many images
    for name in os.listdir(base_path):
        p = os.path.join(base_path, name)
        if os.path.isdir(p):
            # check if this folder contains many image files or directories (class folders)
            files = os.listdir(p)
            # if contains subdirectories, likely class folders
            if any(os.path.isdir(os.path.join(p,f)) for f in files):
                return p, None
            # or if contains many images directly
            img_count = sum(1 for f in files if f.lower().endswith((".jpg",".jpeg",".png")))
            if img_count > 50:
                return p, None
    # 4) fallback to base_path
    return base_path, None

dataset_root, detected_train = find_dataset_root(base_download_path)
print("Detected dataset root:", dataset_root)
print("Detected train folder (if any):", detected_train)

import tensorflow as tf
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input

IMG_SIZE = 224
BATCH_SIZE = 32

if detected_train:
    TRAIN_DIR = detected_train
    possible_val_dirs = [os.path.join(dataset_root, d) for d in ("valid","val","validation","test")]
    VAL_DIR = next((d for d in possible_val_dirs if os.path.isdir(d)), None)
    if VAL_DIR is None:
        print("No separate validation folder found. Will split TRAIN_DIR into train/val.")
        dataset_mode = "split_from_train"
    else:
        print("Using TRAIN_DIR:", TRAIN_DIR, "VAL_DIR:", VAL_DIR)
        dataset_mode = "pre_split"
else:
    print("Using dataset_root (no pre-split found):", dataset_root)
    TRAIN_DIR = dataset_root
    VAL_DIR = None
    dataset_mode = "split_from_train"

def build_from_dirs(train_dir, val_dir=None, img_size=IMG_SIZE, batch_size=BATCH_SIZE):
    if val_dir and os.path.isdir(val_dir):
        train_ds = tf.keras.utils.image_dataset_from_directory(
            train_dir, image_size=(img_size,img_size), batch_size=batch_size, label_mode='categorical', shuffle=True)
        val_ds = tf.keras.utils.image_dataset_from_directory(
            val_dir, image_size=(img_size,img_size), batch_size=batch_size, label_mode='categorical', shuffle=False)
    else:
        seed = 123
        train_ds = tf.keras.utils.image_dataset_from_directory(
            train_dir, image_size=(img_size,img_size), batch_size=batch_size, label_mode='categorical',
            validation_split=0.2, subset='training', seed=seed, shuffle=True)
        val_ds = tf.keras.utils.image_dataset_from_directory(
            train_dir, image_size=(img_size,img_size), batch_size=batch_size, label_mode='categorical',
            validation_split=0.2, subset='validation', seed=seed, shuffle=False)
    AUTOTUNE = tf.data.AUTOTUNE
    train_ds = train_ds.map(lambda x,y: (preprocess_input(x), y), num_parallel_calls=AUTOTUNE)
    val_ds   = val_ds.map(lambda x,y: (preprocess_input(x), y), num_parallel_calls=AUTOTUNE)
    train_ds = train_ds.cache().shuffle(1000).prefetch(AUTOTUNE)
    val_ds   = val_ds.cache().prefetch(AUTOTUNE)
    return train_ds, val_ds

train_ds, val_ds = build_from_dirs(TRAIN_DIR, VAL_DIR, img_size=IMG_SIZE, batch_size=BATCH_SIZE)

for _, y in train_ds.take(1):
    num_classes = y.shape[-1]
print("Number of classes detected:", num_classes)

from tensorflow.keras import layers

data_augmentation = tf.keras.Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.06),
    layers.RandomZoom(0.05),
], name="data_augmentation")

from tensorflow.keras import models, layers
from tensorflow.keras.applications import MobileNetV2

base_model = MobileNetV2(weights='imagenet', include_top=False,
                         input_shape=(IMG_SIZE, IMG_SIZE, 3))
base_model.trainable = False

inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))
x = data_augmentation(inputs)
x = base_model(x, training=False)
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dropout(0.3)(x)
x = layers.Dense(128, activation='relu')(x)
outputs = layers.Dense(num_classes, activation='softmax', dtype='float32')(x)

model = models.Model(inputs, outputs)

model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

EPOCHS = 10 # Define the number of epochs

from tensorflow.keras import callbacks
callbacks_list = [
    callbacks.ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True),
    callbacks.EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True),
    callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2)
]

history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS,
    callbacks=callbacks_list,
    verbose=1
)

import os
import tensorflow as tf
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
try:
    TEST_DIR
except NameError:
    TEST_DIR = os.path.join(dataset_root, "test")

try:
    VAL_DIR
except NameError:
    VAL_DIR = None

def build_test_ds(test_dir, img_size=IMG_SIZE, batch_size=BATCH_SIZE):
    ds = tf.keras.utils.image_dataset_from_directory(
        test_dir,
        image_size=(img_size, img_size),
        batch_size=batch_size,
        label_mode='categorical',
        shuffle=False
    )
    ds = ds.map(lambda x, y: (preprocess_input(x), y), num_parallel_calls=tf.data.AUTOTUNE)
    ds = ds.cache().prefetch(tf.data.AUTOTUNE)
    return ds
if os.path.isdir(TEST_DIR):
    print("Using TEST_DIR:", TEST_DIR)
    test_ds = build_test_ds(TEST_DIR)
elif VAL_DIR and os.path.isdir(VAL_DIR):
    print("TEST_DIR not found — falling back to VAL_DIR for evaluation:", VAL_DIR)
    test_ds = build_test_ds(VAL_DIR)
else:
    print("No TEST/VAL folder found. Creating a test split (10%) from TRAIN_DIR:", TRAIN_DIR)
    seed = 123
    test_ds = tf.keras.utils.image_dataset_from_directory(
        TRAIN_DIR,
        image_size=(IMG_SIZE, IMG_SIZE),
        batch_size=BATCH_SIZE,
        label_mode='categorical',
        validation_split=0.1,
        subset='validation',   # 10% used as test set here
        seed=seed,
        shuffle=False
    )
    test_ds = test_ds.map(lambda x, y: (preprocess_input(x), y), num_parallel_calls=tf.data.AUTOTUNE)
    test_ds = test_ds.cache().prefetch(tf.data.AUTOTUNE)

# Sanity: ensure test_ds is defined
try:
    # print quick summary about test dataset
    num_test_batches = 0
    num_test_examples = 0
    for batch_x, batch_y in test_ds.take(5):  # only peek up to 5 batches
        num_test_batches += 1
        num_test_examples += batch_x.shape[0]
    print(f"Test dataset ready — approx. batches seen: {num_test_batches}, approx. examples: {num_test_examples}")
except Exception as e:
    print("Error inspecting test_ds:", e)
    raise

# Evaluate the model on the chosen test dataset
loss, acc = model.evaluate(test_ds)
print(f"Test Accuracy: {acc*100:.2f}%  — Test Loss: {loss:.4f}")